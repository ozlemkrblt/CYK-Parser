import sys
import os


def read_grammar(filename):
    """ Reads the file grammar.txt and returns a dictionary of production rules. """
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            lines = file.readlines()
    except FileNotFoundError:
        print(f"Error: File {filename} not found.")
        sys.exit(1)

    rules_dict = {}
    nonterminals = set()  # Use a set to collect all non-terminals

    # Process each line to build the grammar rules
    for line in lines:
        left, right = line.strip().split(' -> ')
        right_parts = tuple(right.split())
        nonterminals.add(left)  # Collect LHS non-terminals
        for part in right_parts:
            if part.isalpha() and part.isupper():
                nonterminals.add(part)  # Collect RHS non-terminals

        if left not in rules_dict:
            rules_dict[left] = []
        rules_dict[left].append(right_parts)

    start_symbol = lines[0].strip().split(' -> ')[0]
    return start_symbol, rules_dict, list(nonterminals)


def read_sentences(filename):
    """ Reads the file sentences.txt and returns a list of sentences."""
    try:
        with open(filename, 'r', encoding='utf-8') as file:
            sentences = [line.strip().split() for line in file.readlines()]
    except FileNotFoundError:
        print(f"Error: File {filename} not found.")
        sys.exit(1)

    return sentences


def write_output(results, filename):
    """ Writes the results of the CYK algorithm to an output file."""
    try:
        with open(filename, 'w', encoding='utf-8') as file:
            for result in results:
                file.write(f'{result}\n')
    except IOError:
        print(f"Error: Could not write to file {filename}.")
        sys.exit(1)


def write_visualization(viz_data, filename):
    """ Writes the DOT descriptions of the parse trees to a file."""
    try:
        with open(filename, 'w', encoding='utf-8') as file:
            for sentence, (count, descriptions) in viz_data.items():
                file.write(f'{sentence}\n')
                file.write(f'parses: {count}\n')
                for description in descriptions:
                    file.write(f'graph{{\n{description}}}\n')
    except IOError:
        print(f"Error: Could not write to file {filename}.")
        sys.exit(1)


def cyk_algorithm(string, start_symbol, rules, nonterminals):
    """
    CYK Algorithm to determine if a string is in the language

    :param string : The input string to be parsed
    :param start_symbol: The start symbol of the grammar.
    :param rules: The production rules of the grammar.
    :param nonterminals: List of non-terminal symbols in the grammar.
    :return back[] : an array of backpointing triples.

    """
    n = len(string)
    r = len(rules)

    P = [[[False for _ in range(r)] for _ in range(n)] for _ in range(n + 1)]  # init P array with n x n x r
    # dimensions and populate with False values
    back = [[[[] for _ in range(r)] for _ in range(n)] for _ in range(n + 1)]  # init back-pointer array with n x n x r
    # dimensions and populate with empty values

    # Fill in the tables for unit productions
    for s in range(n):
        for v in range(r):
            if (string[s],) in rules[nonterminals[v]]:
                P[1][s][v] = True

    # Fill P and back for productions
    for l in range(2, n + 1):  # Length of span
        for s in range(n - l + 1):  # Start of span
            for p in range(1, l):  # Partition of span
                for a in range(r):  # Production Ra
                    for production in rules[nonterminals[a]]:
                        if len(production) == 2:
                            b, c = production
                            b_index = nonterminals.index(b)
                            c_index = nonterminals.index(c)
                            if P[p][s][b_index] and P[l - p][s + p][c_index]:
                                P[l][s][a] = True
                                back[l][s][a].append((p, b_index, c_index))

    # Check if the whole string can be generated by the start symbol
    if P[n][0][nonterminals.index(start_symbol)]:
        return back
    else:
        return "not a member of language"


def extract_trees(back, start_symbol_index, sentence_len, nonterminals):
    """
    Extracts parse trees from the backpointer table.

    :param back: The backpointer table.
    :param start_symbol_index: The index of the start symbol.
    :param sentence_len: The length of the input sentence.
    :param nonterminals: List of nonterminals.
    :return: List of parse trees in DOT format.
    """

    def build_tree(l, s, a):
        if l == 1:
            return f'{nonterminals[a]}_{s}'
        else:
            trees = []
            # Iterate over each backpointer for the current span
            for p, b, c in back[l][s][a]:
                left_tree = build_tree(p, s, b)
                right_tree = build_tree(l - p, s + p, c)
                trees.append((left_tree, right_tree))
            return f'{nonterminals[a]} -> {{{" ".join(f"{l} -> {r}" for l, r in trees)}}}'  # combine the left and
                                                                                            # right subtrees
                                                                                            #  into a single production rule

    return [build_tree(sentence_len, 0, start_symbol_index)]


def trees_to_dot(trees):
    dot_descriptions = []

    """
    Converts parse trees to DOT format for visualization.

    :param trees: List of parse trees to be converted.
    :return: List of DOT format descriptions of parse trees.
       
    """

    def tree_to_dot(tree, node_id=0, parent_id=None):

        """
        Recursively converts a parse tree to DOT format.

        :param tree: The parse tree to be converted.
        :param node_id: ID assigned to the current node.
        :param parent_id: ID assigned to the parent node (if any).
        :return: Tuple containing the next available node ID and the DOT format descriptions of the tree.
        """

        node_label = tree[0]

        node_desc = f'{node_id} [label="{node_label}"]'  # create node with an id and label
        edges = []

        child_id = node_id + 1  # first child node
        if len(tree) > 1:
            # if the tree has child nodes, iterate over each child node
            for child in tree[1:]:
                edges.append(f'{node_id} -> {child_id}')  # construct an edge from the current node to the child node
                child_id = tree_to_dot(child, child_id, node_id)  # recursive call for updating the child id

        if parent_id is not None:
            # if the node has a parent, add an edge from the parent to the current node
            edges.append(f'{parent_id} -> {node_id}')
        return child_id, [node_desc] + edges

    for i, tree in enumerate(trees):
        _, dot_tree = tree_to_dot(tree)
        dot_descriptions.append('\n'.join(dot_tree))

    return dot_descriptions


def return_results(start_symbol, rules, nonterminals, sentences):
    """
    Runs the CYK algorithm on the given sentences using the provided grammar,
    and returns the results along with parse tree visualizations.

    """

    results = []
    visualizations = {}
    for sentence in sentences:
        result = cyk_algorithm(sentence, start_symbol, rules, nonterminals)

        if result == "not a member of language":
            results.append(0)
        else:
            results.append(1)
            trees = extract_trees(result, nonterminals.index(start_symbol), len(sentence), nonterminals)
            visualizations[" ".join(sentence)] = (len(trees), trees)

    return results, visualizations


def main(grammar_file, sentences_file, output_dir):
    start_symbol, rules, nonterminals = read_grammar(grammar_file)
    sentences = read_sentences(sentences_file)
    results, visualizations = return_results(start_symbol, rules, nonterminals, sentences)
    output_file = os.path.join(output_dir, 'Ozlem_Karabulut.txt')
    write_output(results, output_file)
    viz_file = os.path.join(output_dir, 'Ozlem_Karabulut_viz.txt')
    write_visualization(visualizations, viz_file)


if __name__ == '__main__':
    if len(sys.argv) != 4:
        print('Usage: python main.py grammar.txt sentences.txt ./')
    else:
        main(sys.argv[1], sys.argv[2], sys.argv[3])
